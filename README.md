# Bleach Wiki RAG Bot

## 1ï¸âƒ£ Introduction
Bleach is one of the most well-known anime and manga series, filled with an extensive lore, complex character relationships, and powerful abilities. However, finding detailed and accurate information across its vast universe can be time-consuming.

Enter **Bleach Wiki RAG Bot**â€”a Retrieval-Augmented Generation (RAG) chatbot that allows users to ask detailed questions about Bleach and receive accurate, context-aware answers. Instead of manually searching through wiki pages, users can simply query the bot and retrieve relevant information instantly.

## 2ï¸âƒ£ Project Overview
This project builds an end-to-end RAG pipeline by:
- **Scraping** structured content from the Bleach Wiki.
- **Processing & Chunking** text for better retrieval.
- **Embedding & Storing** knowledge in a vector database.
- **Retrieving & Generating** accurate responses with a language model.

The system ensures efficient data retrieval, factual consistency, and minimal hallucinations.

### ğŸ“ Directory Structure
```
Bleach_Bot/
â”œâ”€â”€ bleach_wiki/         # Stores all processed data
â”‚   â”œâ”€â”€ raw/            # Raw scraped pages from Bleach Wiki
â”‚   â”œâ”€â”€ processed/      # Cleaned and structured JSON files
â”‚   â”œâ”€â”€ chunks/         # Chunked text data for embeddings
â”‚   â”œâ”€â”€ embeddings/     # Vector embeddings for retrieval
â”‚   â”œâ”€â”€ vector_db/      # ChromaDB storage for fast lookup
â”‚
â”œâ”€â”€ src/                # Core RAG pipeline logic
â”‚   â”œâ”€â”€ scraper/        # Web scraping and preprocessing
â”‚   â”‚   â”œâ”€â”€ page_collector.py # Extracts all page names for scraping
â”‚   â”‚   â”œâ”€â”€ scraper.py       # Scrapes content from Bleach Wiki
â”‚   â”‚   â”œâ”€â”€ preprocess.py    # Cleans and structures raw data
â”‚   â”‚   â””â”€â”€ chunker.py       # Splits text into smaller chunks
â”‚   â”‚
â”‚   â”œâ”€â”€ embedder/       # Embedding logic for retrieval
â”‚   â”‚   â”œâ”€â”€ embed.py    # Converts text into vector embeddings
â”‚   â”‚   â””â”€â”€ vector_store.py  # Stores and retrieves embeddings
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/       # Core retrieval and generation logic
â”‚   â”‚   â”œâ”€â”€ retrieval.py       # Retrieves relevant information
â”‚   â”‚   â”œâ”€â”€ retrieval_chain.py # Manages RAG pipeline
â”‚   â”‚   â”œâ”€â”€ llm.py             # LLM-based response generation
â”‚   â”‚
â”‚   â”œâ”€â”€ chatbot/        # Handles user queries and interaction
â”‚   â”‚   â””â”€â”€ mainbot.py  # Main chatbot logic
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/     # Performance & faithfulness evaluation
â”‚   â”‚   â”œâ”€â”€ evaluation.py  # Computes faithfulness & accuracy
â”‚   â”‚   â””â”€â”€ logging.py     # Logs evaluation results
â”‚   â”‚
â”‚   â”œâ”€â”€ frontend/       # Streamlit-based UI for chatbot
â”‚   â”‚   â”œâ”€â”€ streamlit_app1.py  # Streamlit UI Version 1
â”‚   â”‚   â”œâ”€â”€ streamlit_app2.py  # Streamlit UI Version 2
â”‚
â”œâ”€â”€ README.md           # Documentation & project overview
â”œâ”€â”€ requirements.txt    # Required dependencies
```

---

## 3ï¸âƒ£ Scraper 
### Overview
The scraper module extracts structured data from Bleach Wiki using **Selenium** and **BeautifulSoup**. The data is then cleaned, chunked, and stored for retrieval.

### ğŸ“‚ Components

#### 1ï¸âƒ£ **page_collector.py**
ğŸ”¹ Collects all character names listed in the Bleach Wiki.
ğŸ”¹ Uses Selenium to navigate through pages.
ğŸ”¹ Stores the extracted names for scraping.

#### 2ï¸âƒ£ **scraper.py**
ğŸ”¹ Fetches Bleach Wiki pages using Selenium.
ğŸ”¹ Parses structured content using BeautifulSoup.
ğŸ”¹ Extracts sections, descriptions, and metadata.
ğŸ”¹ Saves results as JSON files in `bleach_wiki/raw/`.

#### 3ï¸âƒ£ **preprocessor.py**
ğŸ”¹ Cleans and processes raw JSON data by:
   - Removing unnecessary elements.
   - Flattening subsections for structured retrieval.
ğŸ”¹ Stores results in `bleach_wiki/processed/`.

#### 4ï¸âƒ£ **chunker.py**
ğŸ”¹ Splits processed text into smaller, meaningful chunks.
ğŸ”¹ Ensures coherence for better retrieval.
ğŸ”¹ Saves chunked text in `bleach_wiki/chunks/`.

---

## 4ï¸âƒ£ Embedder & Vector Storage
### Overview
The embedding module converts text into high-dimensional vector embeddings using **Google's Gemini Model** and stores them in **ChromaDB** for fast similarity-based retrieval.

### ğŸ“‚ Components

#### 1ï¸âƒ£ **Text Embedding with Gemini (embed.py)**
ğŸ”¹ Converts textual chunks into vector embeddings.
ğŸ”¹ Saves them in `.jsonl` format in `bleach_wiki/embeddings/`.
ğŸ”¹ Skips already processed files.

#### 2ï¸âƒ£ **Storing & Retrieving Embeddings (vector_store.py)**
ğŸ”¹ Loads precomputed embeddings and indexes them in **ChromaDB**.
ğŸ”¹ Enables similarity-based retrieval for queries.

ğŸ”¹ **Execution Flow:**
1ï¸âƒ£ Run `embed.py` â†’ Generates vector embeddings.
2ï¸âƒ£ Run `vector_store.py` â†’ Stores embeddings in ChromaDB.
3ï¸âƒ£ Use `retrieval.py` â†’ Retrieves relevant documents.

---

## 5ï¸âƒ£ RAG Pipeline 
### Overview
The **Retrieval-Augmented Generation (RAG) pipeline** enhances LLM responses by retrieving contextually relevant documents before generating answers.

### ğŸ“‚ Components

#### 1ï¸âƒ£ **Retrieval (retrieval.py)**
ğŸ”¹ Fetches relevant information from ChromaDB based on semantic similarity.
ğŸ”¹ Uses vector search to retrieve top-matching chunks.


#### 2ï¸âƒ£ **Generation (llm.py)**
ğŸ”¹ Takes retrieved context and constructs a query-specific prompt.
ğŸ”¹ Generates a response using **Gemini LLM**.


#### 3ï¸âƒ£ **RAG Pipeline Integration (retrieval_chain.py)**
ğŸ”¹ Combines retrieval and generation for **seamless interaction**.

---
